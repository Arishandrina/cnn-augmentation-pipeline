  - [Описание проекта](#описание-проекта)
  - [Структура проекта](#структура-проекта)
  - [Установка](#установка)
  - [Данные](#данные)
  - [Как запускать эксперименты](#как-запускать-эксперименты)
  - [Ключевые выводы](#ключевые-выводы-кратко)

## Описание проекта

Этот репозиторий содержит эксперименты по **аугментации данных для сверточных сетей** на датасете **SVHN**
Реализован пошаговый пайплайн аугментаций, исследуются разные доли аугментированных данных в обучающем наборе, сравниваются модели **SimpleCNN** и **ResNet18Cifar**, а также проводится **distillation** от ResNet к модели‑студенту

---

## Структура проекта

- `config.py` — глобальные настройки: пути (`DATA_DIR`, `MODELS_DIR`, `REPORTS_DIR`), гиперпараметры обучения, сид
- `data_loading.py`  
  - Загрузка SVHN через `torchvision.datasets.SVHN`
  - Подсчёт статистик по каналам (mean/std)
  - Функции для построения `DataLoader`‑ов, в т.ч. с произвольным train‑трансформом для аугментаций
- `augmentations.py`  
  - `get_eval_transform` — базовый трансформ без аугментаций (val/test)
  - `stage1_basic` … `stage5_occlusion` — 5 стадий аугментаций с нарастающей “силой”:  
    геометрия -> цвет -> блюр+шум -> окклюзии 
  - `ProbTransform` — смешивает чистый и аугментированный пайплайны с вероятностью `p_aug`
- `model.py`  
  - `SimpleCNN` — компактная базовая CNN для изображений 32×32
  - `ResNet18Cifar` — адаптированный под CIFAR/SVHN вариант ResNet‑18
- `training.py`  
  - Универсальные циклы обучения/валидации: `train_epoch`, `eval_epoch`, `fit`, `evaluate`
  - Счёт accuracy, macro/weighted F1 и confusion matrix
- `visualization.py`  
  - EDA‑утилиты (распределение классов, гистограммы каналов, яркость/контраст/резкость, средние изображения) 
  - `plot_confusion_matrix` и вспомогательные функции для графиков
- `augmentation_stages.ipynb` — **главный ноутбук проекта**:  
  - базовый эксперимент и поэтапное добавление аугментаций для SimpleCNN 
  - перебор долей аугментированных данных `p_aug` $\in$ `{0, 0.25, 0.5, 0.75, 1.0}`  
  - тепловая карта «стадия × p_aug -> F1_macro»
  - обучение и сравнение ResNet18Cifar
  - подбор гиперпараметров с Optuna
  - distillation: обучение SimpleCNN‑студента от лучшей ResNet‑модели 
- `baseline_model.ipynb` — первоначальный baseline без аугментаций
- `eda.ipynb` — исследовательский анализ данных SVHN (баланс классов, статистики изображений)
- `reports/`  
  - `*_metrics.json` — сохранённые метрики для каждой конфигурации (стадия, `p_aug`, модель, epochs и т.п.) 
  - `optuna.db` — база экспериментов Optuna (игнорируется git‑ом)
- `models/` — чекпоинты моделей (`*.pth`, игнорируются git‑ом)
- `data/raw/` — сырые файлы SVHN (`train_32x32.mat`, `test_32x32.mat`)
- `requirements.txt` — список Python‑зависимостей, необходимых для запуска проекта

---
## Установка

1. Клонировать репозиторий:

   ```bash
   git clone https://github.com/Arishandrina/cnn-augmentation-pipeline.git
   cd cnn-augmentation-pipeline
   ```
2. (Опционально) создать виртуальное окружение:

   ```bash
   python -m venv .venv
   source .venv/bin/activate      # Windows: .venv\Scripts\activate
   ```
3. Установить зависимости из `requirements.txt`:

   ```bash
   pip install -r requirements.txt
   ```

---

## Данные

- Используется датасет **SVHN** (Street View House Numbers), формат 32×32 RGB
- Данные скачиваются автоматически при первом запуске кода через `torchvision.datasets.SVHN` и сохраняются в `data/raw/`
- Тяжёлые файлы (`data/raw/*`, `models/*.pth`, `reports/*.db`) добавлены в `.gitignore` и не попадают в репозиторий

---

## Как запускать эксперименты

### Через Jupyter‑ноутбуки (основной сценарий)

1. Запустить Jupyter:

   ```bash
   jupyter lab       # или jupyter notebook
   ```
   
2. Открыть и по желанию прогнать:
   - `eda.ipynb` — EDA по SVHN
   - `augmentation_stages.ipynb` — основной ноутбук:
     - подсчёт mean/std и определение трансформов
     - эксперименты с 5 стадиями аугментаций для SimpleCNN
     - грид по `p_aug` и построение тепловой карты F1
     - сравнение с ResNet18Cifar
     - подбор гиперпараметров ResNet через Optuna
     - обучение студента SimpleCNN по схеме distillation
     - формирование основных графиков и таблиц для отчёта

В каждом крупном блоке ноутбука есть комментариями, что именно происходит

### Повторное использование кода в своих скриптах

Можно подключать свои модели или аугментации, сохраняя общий тренировочный пайплайн

---

## Ключевые выводы

- **Пошаговые аугментации.** Добавление всё более сложных аугментаций (геометрия -> цвет -> блюр+шум -> окклюзии) позволяет оценить вклад каждого класса преобразований в качество модели
- **Доля аугментированных данных.** Эксперименты с `p_aug` $\in$ `{0, 0.25, 0.5, 0.75, 1.0}` показывают, что умеренное количество аугментаций (примерно 0–0.25) даёт лучший F1, при `p_aug = 1.0` качество заметно падает
- **Сравнение моделей.**  
  - `SimpleCNN` служит компактным baseline 
  - `ResNet18Cifar` достигает чуть более высокого F1_macro на SVHN за счёт большего числа параметров
- **Distillation.** Студент `SimpleCNN`, обученный с использованием знаний teacher‑модели ResNet, почти догоняет её по F1, но она намного легче и быстрее для инференса

Подробные графики (heatmap, learning curves, confusion matrix, per‑class F1) находятся в `augmentation_stages.ipynb`

  | Модель                 | Стадия        | p_aug | F1_macro (test) |
  |------------------------|--------------|:----:|:----------------:|
  | SimpleCNN              | stage1_basic | 0.00 | 0.929            |
  | SimpleCNN              | stage5_occ   | 0.25 | 0.928            |
  | ResNet18Cifar          | stage1_basic | 0.04 | 0.932            |
  | SimpleCNN (KD student) | stage1_basic | 0.04 | 0.931            |


  ## Пример результатов

  - **Тепловая карта F1 по стадии и доле аугментаций**

<img width="729" height="370" alt="image" src="https://github.com/user-attachments/assets/f860d891-83af-4a40-bcce-71cf34709331" />


  - **Learning curves для лучшей конфигурации ResNet18Cifar**

<img width="1100" height="299" alt="image" src="https://github.com/user-attachments/assets/ed2a7893-9372-4a0b-bd87-da990d8d6286" />

  - **Confusion matrix для лучшей модели (Teacher ResNet)**

<img width="576" height="490" alt="image" src="https://github.com/user-attachments/assets/2e29328b-23c6-4b18-b7fb-d94161fccd8e" />


---

## Воспроизводимость

- Сиды NumPy, Python и PyTorch фиксируются через `set_seed` в `data_loading.py`
- Пути и базовые гиперпараметры сосредоточены в `config.py`
- Для каждого эксперимента сохраняется `*_metrics.json` в `reports/`, что позволяет строить сводные таблицы и графики без повторного обучения
